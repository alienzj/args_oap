# ARGs_OAP v2.4 manual 
Here posted the source code of package `args_oap` + its usage info 

## Changes
The change log of this version (2022.01.12) includes:  
1. pipeline modification  
   We removed bbmap thus we can treat single end reads.  


## Installation
+ via conda (only available for `linux-64, python=3.7`)

```bash
conda install -c bioconda -c xiaole99 args_oap=2.3.7
#conda install -c bioconda -c hkuenvbio args_oap=2.4
```
please note that at this moment only python=3.7 is support, if python!=3.7, you may want to create a new conda environment:
    
```bash
conda create -n args_oap -c xiaole99 -c bioconda args_oap=2.3.7 python=3.7
#conda create -n args_oap -c hkuenvbio -c bioconda args_oap=2.4 python=3.7
source activate args_oap
```

+ via source

args_oap depends on `diamond>=0.9.24`, `minimap2`, `fastp`, `samtools`, `blast`. If your system has all the dependencies, then:
```bash
git clone -b test https://github.com/xiaole99/args_oap_for_conda
cd args_oap_for_conda
git clone -b test https://github.com/xiaole99/args_oap
cd args_oap
python setup.py install # use python3 if needed
```

## Usage 
Two toy examples (100k paired-end reads, 100bp each) are provided in `example/inputdir`:

```bash
# git clone -b test https://github.com/xiaole99/args_oap_for_conda
# cd args_oap_for_conda
# git clone -b test https://github.com/xiaole99/args_oap
# cd args_oap

args_oap stage_one -i example/inputfqs -m example/meta-data.txt -o example/output -f 'fa' -n 8
args_oap stage_two -i example/output/extracted.fa -m example/output/meta_data_online.txt -o example/output -n 8
```
The example result are in testoutdir/  

### todo: need to modify the path in the original perl files, otherwise cannot run
Now the perl files use the binaries in the `bin` folder, need to change the path e.g. `./bin/diamond -> diamond` in future updates

###  Before run the above command, need to prepare the meta-data file of your samples
To run the stage one pipeline, users need to 
1. Put all your paired-end fastq/fasta files into one directory (notice that the name of your fastq files should be Name_1.fq and Name_2.fq).  
2. Prepare relative meta-data.txt file.  

Tips:     
* You need keep the first and second column's name as SampleID and Name  
* The SampleID are required to be unique numbers counting from 1 to 2 to 3 etc.  
* Category is the classification of your samples into groups and we will colored your samples in PcoA by this informaton  
* The meta-data table should be separated by tabular for each of the items   
* The Name of each sample should be the fastq file names for your pair-end Illumina sequencing data, your fastq files will automatically be recognized by Name_1.fq and Name_2.fq, so you need to keep the name consistent with your fq file name. (if you files are end with .fastq or .fasta, you need to change them to end with .fq or .fa)  
   
**Please make sure the meta-data file is pure txt format, if you edit the file under windows, using notepad++ and check the end of each line by cliking View-> Show Symbol -> Show All Characters. If the line is end up with CRLF, please remove the CR by replace \r to nothing in the replace dialogue frame.**

The meta-data.txt shall look like this:

SampleID | Name | Category |ReadLength  
---------|------|-------|----  
 1       | STAS | ST       |100  
 2       | SWHAS104 | SWH  |100  
  


### (optional) For very big data to run stage two  
For users have very big data and prefer complex running:  
1. users run locally by themselves to get the blastx outfmt 6 format resutls by alighment against SARG2.2.  
**A typical scene is that users can paralelly run the blastx on clusters by multi-nodes, and then merge the blastx output as the input for the -b option.**  
2. Prerequest   
    a. download the whole fold of this repo.      
    b. install R packages **vegan, labdsv, ggplot2 and scales**  (Enter R and use install.packages(pkgs="vegan") to install these packages).  
3. use -b option for the stage two script:   

```
args_oap stage_two -i extracted.fa -m meta_data_online.txt -o testout -b merge_blastx.out.txt  
```


### (optional) Stage two pipeline on Galaxy system and download results  
Go to http://smile.hku.hk/SARGs  and using the module ARG_OAP.    
  
1. Using **ARG_OAP** -> **Upload Files** module to upload the extracted fasta file and meta_data_online.txt file generated in stage one into Galaxy    
2. Click **ARG_OAP** and **Ublast_stagetwo**, select your uploaded files    
3. For \"Column in Metadata:\" chose the column you want to classify your samples (default: 3)  
  
Click **Execute** and you can find four output files for your information  
  
After a while or so, you will notice that their are four files generated for your information.    
   
**File 1 and 2**: PcoA figures of your samples and other environment samples generated by ARGs abundance matrix normalization to 16s reads number and cell number    
**File 3 and 4**: Other tabular mother tables which including the profile of ARGs type and sub type information, as long as with other environment samples mother table. File3 results of ARGs abundance normalization aganist 16S reads number; File 4 results of ARGs abundance normalization aganist cell number  
  
  
  
There are some questions raised by users, please refer to the [FAQ](https://github.com/biofuture/Ublastx_stageone/wiki/FAQ) for details.  To run ARG OAP locally, users should download the source code into local computer system (Unix/Linux). Users can upload the generated files for stage two onto our Galaxy analysis platform (http://smile.hku.hk/SARGs) or use the local version of stage two script.   
  
---    
**Notice:**  
  
This tools only provide the required scripts for ARGs-OAP1.0/2.0 pipeline  
  
This pipeline is distributed in the hope to achieve the aim of management of antibiotic resistant genes in envrionment, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.This pipeline is only allowed to be used for non-commercial and academic purpose.  
  
**The SARG database is distributed only freely used for academic prupose, any commercial use should require the agreement from the developer team.**   
